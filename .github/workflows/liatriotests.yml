name: Apprentice GitHub Actions

on:
  push:
    branches:
      - "GitHub"
      - "Kubernetes"
      - "Docker"
      - "Presentation"
      - "Version"
      - "ArgoCD"
  pull_request:
    branches: [main]

# on:
#   workflow_run:
#     workflows: ["Trigger Workflow"]
#     types:
#       - completed

concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: false

# concurrency:
#   group: deploy-lock
#   cancel-in-progress: false

# concurrency:
#   group: repo-wide-lock
#   cancel-in-progress: false

# Prevent Multiple Actions from happening at once on the same  branch.
# This does not stop Pull Requests from running at the same time as push.
# concurrency:
#   group: ${{ github.workflow }}-${{ github.ref }}
# group: ci-${{ github.ref }}

env:
  IMAGE_NAME: liatrio-api
  DOCKER_REPO: apptemp/liatrio
  PORT: 80

jobs:
  liatriotests: # Name Required for passing the pull  request checks
    # Security scan wanted these labelled
    permissions:
      contents: write
      packages: read
    env:
      DEPLOY_ENV: ${{ github.event_name == 'pull_request' && 'staging' || 'dev' }}
      BRANCH_NAME: ${{ github.ref_name }}
    # Static Analsysis phase. Can't use DEPLOY_ENV from above since that happens after Static Analysis
    environment: ${{ github.event_name == 'pull_request' && 'staging' || 'dev' }}
    # build:
    # Runner using version
    runs-on: ubuntu-24.04
    timeout-minutes: 5
    outputs:
      NEW_VERSION: ${{ steps.set-version.outputs.NEW_VERSION }}
    steps:
      # checkout@v4 using Sha 3-13-25
      - name: Checkout code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

      - name: ‚≠ê Build Docker Image
        run: docker build -t $IMAGE_NAME .

      - name: ‚≠ê Run Docker
        run: docker run -d -p $PORT:$PORT $IMAGE_NAME

      # liatrio/github-actions/apprentice-action@v1.0.0 3-13-25
      - name: ‚≠ê Run Liatrio 6 tests
        uses: liatrio/github-actions/apprentice-action@0b41561cca6822cc8d880fe0e49e7807a41fdf91

      - name: Log in to Docker Hub
        # If success just in case an if: failure() is ever used
        # Want to make sure that everything worked before starting the upload process
        if: success()
        # uses: docker/login-action@v2 3-13-25
        uses: docker/login-action@465a07811f14bebb1938fbed4728c6a1ff8901fc
        with:
          username: ${{ secrets.DOCKER_USERNAME }}
          password: ${{ secrets.DOCKER_PASSWORD }}

      - name: ‚≠ê Set Version Tag Based on Branch
        id: set-version
        run: |
          # Extract and normalize branch name (only letters)
          BRANCH_NAME=$(echo "${GITHUB_REF#refs/heads/}" | tr -cd 'a-zA-Z')
          echo "Branch Name: $BRANCH_NAME"

          # Try to fetch the current version dynamically using gh CLI
          CURRENT_VERSION=$(gh variable get "$BRANCH_NAME" --env "$DEPLOY_ENV" --repo $GITHUB_REPOSITORY --json name,value --jq '.value' || echo "")

          if [[ -z "$CURRENT_VERSION" ]]; then
            CURRENT_VERSION="0.0.0"
          fi

          echo "Current Version: $CURRENT_VERSION"

          # Function to increment version (adds 0.0.1)
          increment_version() {
            local version=$1
            IFS='.' read -r major minor patch <<< "$version"  # Extract version numbers
            patch=$((patch + 1))  # Increment patch version
            echo "${major}.${minor}.${patch}"
          }

          # Get new version (incremented)
          NEW_VERSION=$(increment_version "$CURRENT_VERSION")

          # Export version to GitHub Actions
          echo "NEW_VERSION=${NEW_VERSION}" >> $GITHUB_ENV
          echo "BRANCH_NAME=${BRANCH_NAME}" >> $GITHUB_ENV

          # Print new version for debugging
          echo "New Version: $NEW_VERSION"

          # Update the GitHub Actions environment variable for the branch with the new version
          gh variable set "$BRANCH_NAME" --body "$NEW_VERSION" --env "$DEPLOY_ENV" --repo $GITHUB_REPOSITORY
        env:
          GH_TOKEN: ${{ secrets.LIAPATS }}

      # Creates a latest and a time stamped version making manual rollbacks easier if needed
      - name: ‚≠ê Tag Docker Image
        if: success()
        run: |
          docker tag $IMAGE_NAME $DOCKER_REPO:latest
          docker tag $IMAGE_NAME $DOCKER_REPO:${BRANCH_NAME}${NEW_VERSION}

      - name: ‚≠ê Push Docker Image
        if: success()
        run: |
          docker push $DOCKER_REPO:latest
          docker push $DOCKER_REPO:${BRANCH_NAME}${NEW_VERSION}

      - name: ‚≠ê Rename Container
        run: |
          echo "${NEW_VERSION}"
          D_OLD_IMAGE_LINE="image: docker.io/${DOCKER_REPO}:"
          D_NEW_TAG="${BRANCH_NAME}${NEW_VERSION}"
          sed -i "s|${D_OLD_IMAGE_LINE}.*|${D_OLD_IMAGE_LINE}${D_NEW_TAG}|" ArgoManifest/deployment.yaml

      - name: ‚≠ê Commit and Push deployment.yaml change
        env:
          GH_TOKEN: ${{ secrets.ARGO_ADD }}
        run: |
          git config user.name "Auto Deployer"
          git config user.email "bot@liatrio.com"
          git checkout "${GITHUB_REF_NAME}"
          git add ArgoManifest/deployment.yaml
          if git diff --cached --quiet; then
            echo "‚úÖ No changes to commit"
          else
            git commit -m "Automated update of deployment.yaml [skip ci]"
            git remote set-url origin https://x-access-token:${GH_TOKEN}@github.com/${GITHUB_REPOSITORY}.git
            git push origin HEAD:${GITHUB_REF_NAME}
          fi

  GCloud:
    # build :
    needs: liatriotests
    # if: false

    env:
      GKE_CLUSTER: cluster-1
      GKE_REGION: us-central1-a
      NEW_VERSION: ${{ needs.liatriotests.outputs.NEW_VERSION }}
      DEPLOY_ENV: ${{ github.event_name == 'pull_request' && 'staging' || 'dev' }}
      BRANCH_NAME: ${{ github.ref_name }}
    # Runner using version
    runs-on: ubuntu-24.04
    timeout-minutes: 15
    # Checks out the Repo code
    permissions:
      contents: read
    steps:
      # checkout@v4 using Sha 3-13-25
      - name: Checkout code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

      # - uses: "google-github-actions/auth@v2"
      - uses: "google-github-actions/auth@6fc4af4b145ae7821d527454aa9bd537d1f2dc5f"
        with:
          credentials_json: "${{ secrets.GOGLE_CREDS }}"

      # uses: google-github-actions/setup-gcloud@v2 3-13-25
      - name: Set up Google Cloud SDK
        uses: google-github-actions/setup-gcloud@6189d56e4096ee891640bb02ac264be376592d6a

      - name: Check if kubectl is installed
        run: kubectl version --client

      - name: Install gke-gcloud-auth-plugin
        run: |
          gcloud components install gke-gcloud-auth-plugin
          echo "export USE_GKE_GCLOUD_AUTH_PLUGIN=True" >> ~/.bashrc
          source ~/.bashrc

      - name: Clusters List
        run: gcloud container clusters list

        # Output used in case this were to be a multi stage
      - name: Check if Cluster Exists
        id: check-cluster
        run: |
          CLUSTER_EXISTS=$(gcloud container clusters list --region $GKE_REGION --filter="name=${GKE_CLUSTER}" --format="value(name)")
          if [[ -z "$CLUSTER_EXISTS" ]]; then
            echo "ERROR: Kubernetes cluster '${GKE_CLUSTER}' not found in region '${GKE_REGION}'"
            echo "CREATE_CLUSTER=false" >> $GITHUB_ENV
            echo "CREATE_CLUSTER=false" >> $GITHUB_OUTPUT
          else
            echo "Cluster '${GKE_CLUSTER}' exists. Proceeding with deployment."
            echo "CREATE_CLUSTER=true" >> $GITHUB_ENV
            echo "CREATE_CLUSTER=true" >> $GITHUB_OUTPUT
          fi

      - name: ‚≠ê Provision Cluster
        if: steps.check-cluster.outputs.CREATE_CLUSTER == 'false'
        run: |
          echo "Provisioning GKE Cluster from k8s/cluster.txt"
          # gcloud components install beta --quiet # Install beta # IF needed
          chmod +x k8s/cluster.txt  # Ensure it's executable
          bash k8s/cluster.txt --quiet &      # Run the cluster creation command
          echo "Cluster creation started! Running in background, next step is used. This is to prevent timeout"

      - name: Wait for Cluster Readiness
        run: |
          echo "Waiting for cluster to be ready"
          for ((i=1; i<=10; i++)); do
            STATUS=$(gcloud container clusters describe ${GKE_CLUSTER} --region ${GKE_REGION} --format="value(status)")

            if [[ "$STATUS" == "RUNNING" ]]; then
              echo "Cluster is now RUNNING."
              exit 0
            fi
            if [[ "$STATUS" == "PROVISIONING" ]]; then
              echo "Cluster is (Status: $STATUS). Adding an extra 30 seconds of wait time"
              sleep 30
            fi

            echo "Attempt $i/10: Cluster '${GKE_CLUSTER}' is still not ready. (Status: $STATUS)"
            sleep 30
          done

          echo "Cluster '${GKE_CLUSTER}' did not become READY after 10 attempts. Exiting."
          exit 1

      - name: Get Kubernetes Credentials
        run: gcloud container clusters get-credentials $GKE_CLUSTER --region $GKE_REGION

      - name: ‚≠ê Print Environment
        run: echo "Deploying to $DEPLOY_ENV"

      - name: ArgoCD Install
        run: |
          if ! kubectl get ns argocd &> /dev/null; then
            echo "ArgoCD not found ‚Äî installing..."
            curl -L https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml -o argocd-install.yaml
            kubectl create namespace argocd
            kubectl apply -n argocd -f ArgoSetup/argocd-install.yaml
          else
            echo "‚úÖ ArgoCD already installed ‚Äî skipping setup."
          fi

      - name: ArgoCD CLI
        run: |
          if ! which argocd >/dev/null 2>&1 || ! argocd version --client >/dev/null 2>&1; then
            echo "üîß Argo CD CLI not found or broken ‚Äî installing..."
            curl -sSL -o argocd-linux-amd64 https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64
            sudo install -m 555 argocd-linux-amd64 /usr/local/bin/argocd
            rm argocd-linux-amd64
            echo "‚úÖ Argo CD CLI installed successfully."
          else
            echo "‚úÖ Argo CD CLI is already installed and working:"
            echo "$(argocd version --client --short)"
          fi

      # Namespaces must be run before the container is deployed
      # WIP dev tag since no staging right now
      - name: ‚≠ê Deploy ArgoCD Appp
        run: |
          kubectl apply -f ArgoSetup/argo-app.yaml
      - name: ‚≠ê Wait for ArgoCD App Sync
        run: |
          export ARGOCD_SERVER=localhost:8080

          # Get the base64-encoded password securely
          ARGOCD_ADMIN_PASSWORD=$(kubectl get secret argocd-initial-admin-secret -n argocd -o jsonpath="{.data.password}")

          # Mask it from logs
          echo "::add-mask::$ARGOCD_ADMIN_PASSWORD"

          # Login using base64-encoded password directly
          argocd login $ARGOCD_SERVER --insecure --username admin --password $(echo "$ARGOCD_ADMIN_PASSWORD" | base64 -d)

          # Wait for the app to sync and become healthy
          argocd app wait liatrio-argocd-api --health --sync
          kubectl rollout status deployment liatrio-deployment-api -n dev #$DEPLOY_ENV

      # # This needs to run before deployment to establish namespaces
      # - name: ‚≠ê Establish Namespaces & GitHub actions applies relevant namespace
      #   run: |
      #     echo "Google Actions adds namespace. Branch is dev. Pull request is staging"
      #     kubectl apply -f k8s/namespaces.yaml

      # - name: Set Kubernetes Context
      #   run: |
      #     kubectl config set-context --current --namespace=$DEPLOY_ENV

      # # Namespaces must be run before the container is deployed
      # - name: ‚≠ê Deploy Container
      #   run: |
      #     kubectl apply -f k8s/deployment.yaml --namespace=$DEPLOY_ENV

      - name: Change-Cause for New Deployment (Shown in Tests)
        run: |
          kubectl annotate deployment liatrio-deployment-api \
            kubernetes.io/change-cause="Deployed: ${NEW_VERSION} from branch: ${BRANCH_NAME} at commit: $GITHUB_SHA" \
            --overwrite -n $DEPLOY_ENV

      - name: Label New Deployment (Shown in Tests)
        run: |
          kubectl label deployment liatrio-deployment-api version=${NEW_VERSION} branch=${BRANCH_NAME} commit=${GITHUB_SHA} --overwrite -n $DEPLOY_ENV

  KubernetesTests:
    if: false
    needs: GCloud
    env:
      GKE_CLUSTER: cluster-1
      GKE_REGION: us-central1-a
      DEPLOY_ENV: ${{ github.event_name == 'pull_request' && 'staging' || 'dev' }}
    # Runner using version
    runs-on: ubuntu-24.04
    timeout-minutes: 15
    # Checks out the Repo code
    permissions:
      contents: read
    steps:
      # checkout@v4 using Sha 3-13-25
      - name: Checkout code
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683

      # - uses: "google-github-actions/auth@v2"
      - uses: "google-github-actions/auth@6fc4af4b145ae7821d527454aa9bd537d1f2dc5f"
        with:
          credentials_json: "${{ secrets.GOGLE_CREDS }}"

      # uses: google-github-actions/setup-gcloud@v2 3-13-25
      - name: Set up Google Cloud SDK
        uses: google-github-actions/setup-gcloud@6189d56e4096ee891640bb02ac264be376592d6a

      - name: Check if kubectl is installed
        run: kubectl version --client

      - name: Install gke-gcloud-auth-plugin
        run: |
          gcloud components install gke-gcloud-auth-plugin
          echo "export USE_GKE_GCLOUD_AUTH_PLUGIN=True" >> ~/.bashrc
          source ~/.bashrc

      - name: Clusters List
        run: gcloud container clusters list

        # Output used in case this were to be a multi stage
      - name: Check if Cluster Exists
        id: check-cluster
        run: |
          CLUSTER_EXISTS=$(gcloud container clusters list --region $GKE_REGION --filter="name=${GKE_CLUSTER}" --format="value(name)")
          if [[ -z "$CLUSTER_EXISTS" ]]; then
            echo "ERROR: Kubernetes cluster '${GKE_CLUSTER}' not found in region '${GKE_REGION}'"
            exit 1
          else
            echo "Cluster '${GKE_CLUSTER}' exists. Proceeding with user setup."
          fi

      - name: Get Kubernetes Credentials
        run: gcloud container clusters get-credentials $GKE_CLUSTER --region $GKE_REGION

      - name: Establish Namespaces
        run: |
          kubectl apply -f k8s/namespaces.yaml

      - name: ‚≠ê Horizontal Pod Autoscaler To 1% to Trigger All Pods
        run: |
          echo "Patching HPA - This should not trigger a rollout"
          kubectl patch hpa liatrio-hpa-api -n $DEPLOY_ENV --patch-file k8s/hpa_test.yaml
          echo ""
          echo "Horizontal Pod Autoscaler Status. Note: CPU may be unknown as that can take a bit to load after a patch. HPA:"
          kubectl get hpa -n $DEPLOY_ENV
          echo ""
          echo "Current Pods:"
          kubectl get pods -n $DEPLOY_ENV

      - name: Wait for HPA to scale
        run: |
          HPA_NAME=liatrio-hpa-api
          MAX_REPLICAS=$(kubectl get hpa $HPA_NAME -n $DEPLOY_ENV -o jsonpath='{.spec.maxReplicas}')
          echo "Waiting for $HPA_NAME to scale to $MAX_REPLICAS replicas..."

          for i in {1..20}; do
            CURRENT_REPLICAS=$(kubectl get deployment liatrio-deployment-api -n $DEPLOY_ENV -o jsonpath='{.status.readyReplicas}')
            echo "Ready replicas: $CURRENT_REPLICAS"

            if [[ "$CURRENT_REPLICAS" == "$MAX_REPLICAS" ]]; then
              echo "$HPA_NAME has reached max replicas ($MAX_REPLICAS)"
              break
            fi

            echo "Waiting... ($i/20)"
            sleep 15
          done

          if [[ "$CURRENT_REPLICAS" != "$MAX_REPLICAS" ]]; then
            echo "Timeout: $HPA_NAME did not reach max replicas."
            exit 1
          fi

      - name: Setting HPA back to normal
        run: |
          kubectl patch hpa liatrio-hpa-api -n $DEPLOY_ENV --patch-file k8s/hpa_reset.yaml

      - name: ‚≠ê RBAC. Role Based Action Control. Create Service Account, Roles, & Binding
        run: |
          echo "Setting up Service Account: github-actions-sa-user to have get & list for namespaces, pods, services, & deployments"      
          kubectl apply -f k8s/rbac.yaml
      - name: ‚≠ê Generate Service Account Token & Test
        run: |
          TOKEN=$(kubectl create token github-actions-sa-user -n github-actions)
          echo "::add-mask::$TOKEN"
          if [ -z "$TOKEN" ]; then
            echo "ERROR: Token generation failed!"
            exit 1
          fi
          echo "Checking Deployments using ServiceAccount"
          echo ""
          echo "Deployments:"
          kubectl --token=$TOKEN get deployment -n $DEPLOY_ENV
          echo ""
          echo "Pods:"
          kubectl --token=$TOKEN get pods -n $DEPLOY_ENV
          echo ""
          echo "Describe Deployment:"
          kubectl --token=$TOKEN describe deployment liatrio-deployment-api -n $DEPLOY_ENV

      - name: ‚≠ê Auth test
        run: |
          echo "Testing Can-I as the GitHub Service Account User"
          echo ""
          echo "Can list Pods under dev?"
          kubectl auth can-i list pods -n dev --as=system:serviceaccount:github-actions:github-actions-sa-user
          echo "Can list Pods under staging?"
          kubectl auth can-i list pods -n staging --as=system:serviceaccount:github-actions:github-actions-sa-user
          echo "Can list Pods under prod?"
          kubectl auth can-i list pods -n prod --as=system:serviceaccount:github-actions:github-actions-sa-user
          echo ""
          echo "Can list namespaces dev? Note: There will be a warning since namespaces aren't namespace scoped"
          kubectl auth can-i list namespaces -n dev --as=system:serviceaccount:github-actions:github-actions-sa-user
          echo "Can list namespaces staging? Note: There will be a warning since namespaces aren't namespace scoped"
          kubectl auth can-i list namespaces -n staging --as=system:serviceaccount:github-actions:github-actions-sa-user
          echo "Can list namespaces prod? Note: There will be a warning since namespaces aren't namespace scoped"
          kubectl auth can-i list namespaces -n prod --as=system:serviceaccount:github-actions:github-actions-sa-user

      - name: ‚≠ê Version Control. Change Cause & Deployment Label
        run: |
          echo "Deployment Label:"
          kubectl get deployment liatrio-deployment-api -n $DEPLOY_ENV --show-labels
          echo ""
          echo "Rollout History:"
          kubectl rollout history deployment liatrio-deployment-api -n $DEPLOY_ENV

      - name: ‚≠ê Patch Rollout
        run: |
          echo "Patching a timestamp to trigger a rollout"
          kubectl patch deployment liatrio-deployment-api -n $DEPLOY_ENV \
           -p "{\"spec\":{\"template\":{\"metadata\":{\"annotations\":{\"rollout-timestamp\":\"trigger-$(date +%s)\"}}}}}"
           echo ""
           echo "Rollout Status"
           kubectl rollout status deployment liatrio-deployment-api -n $DEPLOY_ENV
           echo ""
           echo "Pods:"
           kubectl get pods -n $DEPLOY_ENV
           echo ""
           echo "Change cause to Timestamp"
           kubectl annotate deployment liatrio-deployment-api \
            kubernetes.io/change-cause="Timestamp to trigger a rollout" \
            --overwrite -n $DEPLOY_ENV
           echo "Rollout History:"
           kubectl rollout history deployment liatrio-deployment-api -n $DEPLOY_ENV
      - name: ‚≠ê Rollback
        run: |
          echo "Rollout History:"
          kubectl rollout history deployment liatrio-deployment-api -n $DEPLOY_ENV
          echo ""
          echo "Rolling back to previous version"
          kubectl rollout undo deployment liatrio-deployment-api -n $DEPLOY_ENV
          echo ""
          echo "Rollout History:"
          kubectl rollout history deployment liatrio-deployment-api -n $DEPLOY_ENV
